{
  "model": "./models/llama-2-13b-chat/ggml-model-f16.gguf",
  "params": {
    "contextLength": 4096,
    "batchSize": 512,
    "gpuLayers": 43
  },
  "eval": {
    "batchSize": 512,
    "threadCount": 1
  },
  "predict": {
    "penaltyContextSize": 16,
    "penaltyRepetition": 1.1,
    "penaltyPresence": 0.0,
    "penaltyFrequency": 0.0,
    "topK": 40,
    "tailFreeZ": 1.0,
    "typicalP": 1.0,
    "topP": 0.95,
    "temperature": 0.8
  },
  "bind": "127.0.0.1:2333",
  "connect": "127.0.0.1:2333"
}
